{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Goals </b>\n",
    "\n",
    "- Build a logistic regression classification model using the sci-kit learn library\n",
    "- Describe the sigmoid function, odds, and odds ratios as well as how they relate to logistic regression\n",
    "- Evaluate a model using metrics, such as: classification accuracy/error, confusion matrix, ROC / AOC curves, and loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression is a generalization of the linear regression model, adapted to classification problems\n",
    "- Very popular because it's very fast and interpretable\n",
    "- Not vulnerable to overfitting when you don't have many features\n",
    "- In linear regression, we use a set of quantitative feature variables to predict a continuous response variable. In logistic regression, we use a set of quantitative feature variables to predict probabilities of class membership.\n",
    "- Named for the function used at the core of the method, the logistic function (aka the sigmoid function)\n",
    "- Logistic regression is a linear regression between our feature, X, and the log-odds of our data belonging to a certain class that we will call true for the sake of generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros:\n",
    "\n",
    "- Highly interpretable\n",
    "- Model training and prediction are fast\n",
    "- No tuning is required (most of the time)\n",
    "- Features don't need scaling\n",
    "- Can perform well with a small number of observations\n",
    "- Outputs well-calibrated predicted probabilities\n",
    "\n",
    "### Cons:\n",
    "\n",
    "- Presumes a linear relationship between the features and the log-odds of the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods\n",
    "- Sensitive to irrelevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Formula:\n",
    "![w](http://faculty.cas.usf.edu/mbrannick/regression/gifs/lo8.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a$ = intercept <br>\n",
    "$b$ = coefficient value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Model:\n",
    "![logit](https://camo.githubusercontent.com/0b115390d4832bfca4c423d6b9c3acdaa1ff01b3/68747470733a2f2f7170682e65632e71756f726163646e2e6e65742f6d61696e2d71696d672d3035656463313837336430313033653336303634383632613435353636646261)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding graph represents the logistic function's ability to map our continuous input, x, to a smooth probability curve that begins at the left, near probability 0, and as we increase x, our probability of belonging to a certain class rises naturally and smoothly up to probability 1. \n",
    "\n",
    "\n",
    "In other words:\n",
    "\n",
    "- Logistic regression gives an output of the probabilities of a specific class being true\n",
    "- Those probabilities can be converted into class predictions: for example, if $p >= 0.5$, the models returns 1 and if $p < 0.5$, it returns 0\n",
    "- Logistic function is S-shaped and will always produce values greater than 0 and less than 1\n",
    "- As you know, not all relationships are linear, so LR is not always the right model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key difference in use of coefficients in linear regression vs. logistic regression\n",
    "\n",
    "\n",
    "**Linear Regression:** Betas / coefficients represent the change in the **response variable** for a unit change in x\n",
    "\n",
    "**Logistic Regression:** Betas / coefficients represent the change in the **log-odds ratio** for a unit change in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use sklearn to create fake data\n",
    "data = make_classification(n_samples=800,\n",
    "                           n_features=2,\n",
    "                           class_sep=.89,\n",
    "                           n_informative=2,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=42)\n",
    "\n",
    "df = pd.DataFrame(data[0], columns=['feature_one', 'feature_two'])\n",
    "df['target'] = data[1]\n",
    "\n",
    "# Assign red to class 0 and blue to class 1 (for plotting purposes)\n",
    "\n",
    "# Draw a scatter plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you had to draw a straight line that best separates the two classes, where would you put the line?**\n",
    "\n",
    "\n",
    "Let's focus on feature_two and plot it against the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw a scatter plot of feature_two vs. target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imagine a logit (or S-curve) modeling the relationship between the x and y axes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a logistic regression model on the data above and plot the predicted labels and the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "features = ['feature_two']\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialize and fit the logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score the model \n",
    "score = \n",
    "print(\"The accuracy score is {:.1f}%.\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate label predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the probabilities and the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign predictions to pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign probability of class 1 to pred_probs\n",
    "pred_probs = lr.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine X, y, pred_labels and pred_probs together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "ax = plt.gca()\n",
    "plt.xlabel('Feature Two')\n",
    "plt.ylabel('Target')\n",
    "\n",
    "# Plot feature_two vs. target as a scatter plot\n",
    "\n",
    "\n",
    "# Plot feature_two vs. labels as a line plot\n",
    "\n",
    "\n",
    "# Plot feature_two vs pred_probs as a line plot\n",
    "\n",
    "\n",
    "plt.legend(loc='right', fontsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you see? What is the graph showing us?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to the original dataset with two features and visualize the linear boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot visualizing function\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    \n",
    "    X_max = X.max(axis=0)\n",
    "    X_min = X.min(axis=0)\n",
    "    \n",
    "    xticks = np.linspace(X_min[0], X_max[0], 100)\n",
    "    yticks = np.linspace(X_min[1], X_max[1], 100)\n",
    "    \n",
    "    xx, yy = np.meshgrid(xticks, yticks)\n",
    "    ZZ = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    \n",
    "    Z = ZZ >= 0.5\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y,s=40, alpha=0.4)\n",
    "    \n",
    "    plt.xlabel('Feature One')\n",
    "    plt.ylabel('Feature Two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X and y variables from data using df\n",
    "features = ['feature_one', 'feature_two']\n",
    "target = 'target'\n",
    "\n",
    "# Color code y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialize model and fit it to X and y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imagine what the boundary would look like in this plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lr, X.values, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This graph demonstrates the linearity of the logistic regression algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out the model intercept and coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we interpret logistic regression coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$probability = \\frac {one\\ outcome} {all\\ outcomes}$$\n",
    "\n",
    "$$odds = \\frac {one\\ outcome} {all\\ other\\ outcomes}$$\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- Dice roll of 1: $probability = 1/6$, $odds = 1/5$\n",
    "- Even dice roll: $probability = 3/6$, $odds = 3/3 = 1$\n",
    "- Dice roll less than 5: $probability = 4/6$, $odds = 4/2 = 2$\n",
    "\n",
    "$$odds = \\frac {probability} {1 - probability}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a table of probability vs. odds\n",
    "table = pd.DataFrame({'probability': np.arange(start=0.01, stop=1.0, step=0.01)})\n",
    "table['odds'] = table['probability'] / (1 - table['probability'])\n",
    "\n",
    "# Plot the probability vs. odds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the log-odds to the table by taking the **natural log** of the odds\n",
    "table['logodds'] = np.log(table['odds'])\n",
    "\n",
    "# Plot the probability vs. log odds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The log odds are passed through the logistic function.**\n",
    "\n",
    "Positive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize how the coefficients and intercept can affect the probabilities\n",
    "\n",
    "![logit](http://nbviewer.jupyter.org/github/justmarkham/DAT8/blob/master/notebooks/images/logistic_betas.png)\n",
    "\n",
    "Changing the $\\beta_0$ (or intercept) value shifts the curve horizontally, whereas changing the $\\beta_1$ (or coefficient) value changes the slope of the curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Can you use Spotify data to predict whether or not I will like a song? </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example getting data using APIs\n",
    "import spotipy\n",
    "import json\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "sp = spotipy.Spotify() \n",
    "\n",
    "with open('../../../spotify_credentials.json') as f:\n",
    "    creds = json.load(f)\n",
    "    client_id = creds['client_id']\n",
    "    secret = creds['client_secret']\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=secret) \n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager) \n",
    "\n",
    "playlist = sp.user_playlist(1255971084, '4oKlWPG8WIMhemePCfCyxn') \n",
    "songs = playlist[\"tracks\"][\"items\"] \n",
    "ids = [] \n",
    "\n",
    "for i in range(len(songs)): \n",
    "    ids.append(songs[i][\"track\"][\"id\"]) \n",
    "\n",
    "features = sp.audio_features(ids) \n",
    "df = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "\n",
    "    Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n",
    "    \n",
    "    Danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "\n",
    "    Instrumentalness: Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "    \n",
    "    Loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n",
    "    \n",
    "    Mode: Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
    "\n",
    "    Valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "    \n",
    "    Tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n",
    "\n",
    "    Energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n",
    "    \n",
    "More information here https://developer.spotify.com/web-api/get-audio-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the spotify dataset\n",
    "df = pd.read_pickle(\"../../data/Spotify_Data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick EDA: Summary stats and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print summary stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print summary stats for each label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print correlation matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a logistic regression model on the data to predict whether or not the user will like a certain song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign X and y\n",
    "features = df.drop('target', axis=1).columns\n",
    "target = 'target'\n",
    "\n",
    "\n",
    "# Intialize, fit and score the model\n",
    "\n",
    "print(\"The model produces an accuracy score of {:.1f}%\".format(score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that a good or bad score? To find out, let's compare it to the null accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the null accuracy (aka the benchmark score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a table of the coefficients and odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe of coefficients and their values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odds ratio**: the ratio of the odds after increasing $X_i$ by 1 to the odds before increasing $X_i$ by 1. Therefore, $odds\\_ratio - 1$ can be interpreted as the percentage change in the odds for a 1 unit change in $X_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the odds ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![s](http://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positives (TP):** Number of correct positive predictions\n",
    "\n",
    "**True Negatives (TN):** Number of correct negative predictions\n",
    "\n",
    "**False Positives (FP):** Number incorrect positive predictions\n",
    "\n",
    "**False Negatives (FN):** Number of incorrect negative predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall** (also known as *sensitivity* or the *true positive rate*): Out of all the positive labels, what percentage were predicted correctly?\n",
    "\n",
    "**Precision:** Out of all the positive predictions, what percentage have a positive label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positive Rate:** The number of incorrect positive predictions divided by number of negative labels\n",
    "\n",
    "**True Negative Rate** (also known as *specificity*): The number of correct negative predictions divided by number of negative labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula Table\n",
    "![a](http://www.chioka.in/wp-content/uploads/2013/08/Metrics-Table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix with Metrics\n",
    "\n",
    "![s](https://eus-www.sway-cdn.com/s/4YEmvTlyess2YF1M/images/VfcIF1yrYJrvLl?quality=1071&allowAnimation=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create confusion matrix for the Spotify data and calculate recall and precision scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pass the targets and predictions into a confusion matrix\n",
    "cm = confusion_matrix(y, lr.predict(X))\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were a spotify data scientist, would you want a model that produces more false negatives or false positives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate precision and recall scores with sklearn\n",
    "\n",
    "print(\"The precision is {:.1f}% and the recall is {:.1f}%.\".format(precision * 100, recall * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No function for false positive (fall out) scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the ROC Curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![w](https://chrisalbon.com/images/machine_learning_flashcards/Receiver_Operating_Characteristic_print.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(X)[:,1]\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(y, y_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls='--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the area under the curve using roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the relationship between the thresholds and FPR and TPR?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot ROC_curve again but this time annotate the curve with the threshold value\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls='--')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "for label, x, y in zip(threshold[::25], false_positive_rate[::25], true_positive_rate[::25]):\n",
    "    plt.annotate(\"{0:.2f}\".format(label), xy=(x, y + .04))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot threshold vs. FPR / TPR on the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(threshold, false_positive_rate, linewidth=5, label='False Positive Rate')\n",
    "plt.plot(threshold, true_positive_rate, linewidth=5, label='True Positive Rate')\n",
    "\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel(\"True / False Positive Rate\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see here? Why are is there a negative correlation in both lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Logistic regression:\n",
    "- http://www.dataschool.io/guide-to-logistic-regression/\n",
    "- https://onlinecourses.science.psu.edu/stat504/node/149\n",
    "- https://www.youtube.com/watch?v=_Po-xZJflPM\n",
    "- https://www.youtube.com/watch?v=gNhogKJ_q7U\n",
    "- https://www.youtube.com/watch?v=fJ53tIDbvTM\n",
    "\n",
    "Evalution:\n",
    "- http://www.dataschool.io/roc-curves-and-auc-explained/\n",
    "- http://people.inf.elte.hu/kiss/13dwhdm/roc.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
