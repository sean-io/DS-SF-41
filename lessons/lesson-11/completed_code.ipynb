{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>urlid</th>\n",
       "      <th>boilerplate</th>\n",
       "      <th>alchemy_category</th>\n",
       "      <th>alchemy_category_score</th>\n",
       "      <th>avglinksize</th>\n",
       "      <th>commonlinkratio_1</th>\n",
       "      <th>commonlinkratio_2</th>\n",
       "      <th>commonlinkratio_3</th>\n",
       "      <th>commonlinkratio_4</th>\n",
       "      <th>...</th>\n",
       "      <th>linkwordscore</th>\n",
       "      <th>news_front_page</th>\n",
       "      <th>non_markup_alphanum_characters</th>\n",
       "      <th>numberOfLinks</th>\n",
       "      <th>numwords_in_url</th>\n",
       "      <th>parametrizedLinkRatio</th>\n",
       "      <th>spelling_errors_ratio</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bloomberg.com/news/2010-12-23/ibm-p...</td>\n",
       "      <td>4042</td>\n",
       "      <td>{\"title\":\"IBM Sees Holographic Calls Air Breat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0.789131</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5424</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.07913</td>\n",
       "      <td>0</td>\n",
       "      <td>IBM Sees Holographic Calls Air Breathing Batte...</td>\n",
       "      <td>A sign stands outside the International Busine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  urlid  \\\n",
       "0  http://www.bloomberg.com/news/2010-12-23/ibm-p...   4042   \n",
       "\n",
       "                                         boilerplate alchemy_category  \\\n",
       "0  {\"title\":\"IBM Sees Holographic Calls Air Breat...         business   \n",
       "\n",
       "  alchemy_category_score  avglinksize  commonlinkratio_1  commonlinkratio_2  \\\n",
       "0               0.789131     2.055556           0.676471           0.205882   \n",
       "\n",
       "   commonlinkratio_3  commonlinkratio_4  \\\n",
       "0           0.047059           0.023529   \n",
       "\n",
       "                         ...                          linkwordscore  \\\n",
       "0                        ...                                     24   \n",
       "\n",
       "   news_front_page  non_markup_alphanum_characters  numberOfLinks  \\\n",
       "0                0                            5424            170   \n",
       "\n",
       "   numwords_in_url  parametrizedLinkRatio  spelling_errors_ratio label  \\\n",
       "0                8               0.152941                0.07913     0   \n",
       "\n",
       "                                               title  \\\n",
       "0  IBM Sees Holographic Calls Air Breathing Batte...   \n",
       "\n",
       "                                                body  \n",
       "0  A sign stands outside the International Busine...  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read in the dataset\n",
    "df = pd.read_csv(\"../../data/stumbleupon.tsv\", sep='\\t')\n",
    "\n",
    "# Parse out the title and body of the article\n",
    "df['title'] = df['boilerplate'].map(lambda x: json.loads(x).get('title', ''))\n",
    "df['body'] = df['boilerplate'].map(lambda x: json.loads(x).get('body', ''))\n",
    "\n",
    "# Show a preview of the data\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting \"Greeness\" of Content\n",
    "\n",
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender. A description of the columns is below:\n",
    "\n",
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "title|string|Title of the article\n",
    "body|string|Body text of article\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonlinkratio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonlinkratio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonlinkratio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonlinkratio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are 'evergreen' sites?\n",
    "\n",
    "> Evergreen sites are those that are always relevant.  As opposed to breaking news or current events, evergreen websites are relevant no matter the time or season. \n",
    "\n",
    "> A sample of URLs is below, where label = 1 are 'evergreen' websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821          http://www.smokehelp.org/html/how_soon.html\n",
       "5093    http://itechfuture.com/intelligent-milk-cartons/\n",
       "6612    http://www.worldoffemale.com/ratatouille-recipe/\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label'] == 1]['url'].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exercise \\#1: In pairs, brainstorm 3 - 5 features you could develop that would be useful for predicting evergreen websites.\n",
    "> ###  Exercise \\#2: After looking at the dataset, can you model or quantify any of the characteristics you wanted?\n",
    "- Ex: If you believe high-image content websites are likely to be evergreen, how can you build a feature that represents that?\n",
    "- Ex: If you believe weather content is likely NOT to be evergreen, how might you build a feature that represents that?\n",
    "\n",
    "### Split up and develop 1-3 of the those features independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "5       0.0\n",
       "6       0.0\n",
       "7       0.0\n",
       "8       0.0\n",
       "9       1.0\n",
       "10      0.0\n",
       "11      0.0\n",
       "12      0.0\n",
       "13      0.0\n",
       "14      0.0\n",
       "15      0.0\n",
       "16      0.0\n",
       "17      0.0\n",
       "18      0.0\n",
       "19      0.0\n",
       "20      0.0\n",
       "21      1.0\n",
       "22      0.0\n",
       "23      0.0\n",
       "24      0.0\n",
       "25      0.0\n",
       "26      0.0\n",
       "27      1.0\n",
       "28      0.0\n",
       "29      0.0\n",
       "       ... \n",
       "7365    0.0\n",
       "7366    0.0\n",
       "7367    0.0\n",
       "7368    1.0\n",
       "7369    1.0\n",
       "7370    0.0\n",
       "7371    1.0\n",
       "7372    0.0\n",
       "7373    1.0\n",
       "7374    0.0\n",
       "7375    1.0\n",
       "7376    1.0\n",
       "7377    0.0\n",
       "7378    1.0\n",
       "7379    1.0\n",
       "7380    0.0\n",
       "7381    0.0\n",
       "7382    1.0\n",
       "7383    0.0\n",
       "7384    1.0\n",
       "7385    0.0\n",
       "7386    1.0\n",
       "7387    0.0\n",
       "7388    0.0\n",
       "7389    0.0\n",
       "7390    0.0\n",
       "7391    0.0\n",
       "7392    0.0\n",
       "7393    0.0\n",
       "7394    0.0\n",
       "Name: body, Length: 7395, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'].str.lower().str.contains('recipe').astype(float, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \\#3: Does being a news site affect evergreeness?\n",
    "Compute or plot the percentage of news related evergreen sites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_news\n",
       "1    0.516916\n",
       "?    0.507562\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('is_news')['label'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \\#4: Does category in general affect evergreeness? \n",
    "Plot the rate of evergreen sites for all Alchemy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alchemy_category\n",
       "?                     0.502135\n",
       "arts_entertainment    0.371945\n",
       "business              0.711364\n",
       "computer_internet     0.246622\n",
       "culture_politics      0.457726\n",
       "gaming                0.368421\n",
       "health                0.573123\n",
       "law_crime             0.419355\n",
       "recreation            0.684296\n",
       "religion              0.416667\n",
       "science_technology    0.456747\n",
       "sports                0.205263\n",
       "unknown               0.333333\n",
       "weather               0.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('alchemy_category')['label'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \\#5: How many articles are there per category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?                     2342\n",
       "recreation            1229\n",
       "arts_entertainment     941\n",
       "business               880\n",
       "health                 506\n",
       "sports                 380\n",
       "culture_politics       343\n",
       "computer_internet      296\n",
       "science_technology     289\n",
       "gaming                  76\n",
       "religion                72\n",
       "law_crime               31\n",
       "unknown                  6\n",
       "weather                  4\n",
       "Name: alchemy_category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['alchemy_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \\#6: Create a feature for the title containing the word 'recipe'. \n",
    "Is the % of evegreen websites higher or lower on pages that have recipe in the the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['has_recipe'] = df['body'].str.lower().str.contains('recipe').astype(float, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Build a decision tree model to predict the \"evergreeness\" of a given website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52204670972542788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cls = DecisionTreeClassifier()\n",
    "\n",
    "features = ['image_ratio', 'html_ratio', 'lengthyLinkDomain']\n",
    "target = 'label'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "      \n",
    "# Fits the model\n",
    "cls.fit(X, y)\n",
    "\n",
    "# Using cross val score to just look at the k-fold cross validation scores on a specific model\n",
    "cross_val_score(cls, X, y, scoring='roc_auc', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Evaluate the decision tree using cross-validation; use AUC as the evaluation metric. Add your custom features in to see if there is an improvement relative to the previous model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62861602160341756"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Replace the missing values with 0\n",
    "df['has_recipe'] = df['has_recipe'].fillna(0)\n",
    "\n",
    "new_X = df[features + ['has_recipe']]\n",
    "cross_val_score(cls, new_X, y, scoring='roc_auc', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Adjusting Decision Trees to Avoid Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore the hyperparameters in the decision model by adjusting the maximum number of questions (max_depth) or the minimum number of records in each final node (min_samples_leaf). You can do this manually or through gridsearchCV [(documentation)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54677001348099863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = DecisionTreeClassifier(max_depth=2,\n",
    "                             min_samples_leaf=5)\n",
    "cls.fit(X, y)\n",
    "cross_val_score(cls, X, y, scoring='roc_auc', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Build a random forest model to predict the evergreeness of a website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest:  0.562969896564\n",
      "Logistic regression:  0.536684084649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "cls = RandomForestClassifier(n_estimators=50)\n",
    "cls.fit(X, y)\n",
    "print 'Random forest: ', cross_val_score(cls, X, y, scoring='roc_auc', cv=5).mean()\n",
    "\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X, y)\n",
    "print 'Logistic regression: ', cross_val_score(logr, X, y, scoring='roc_auc', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Extracting importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>html_ratio</td>\n",
       "      <td>0.540563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_ratio</td>\n",
       "      <td>0.456731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lengthyLinkDomain</td>\n",
       "      <td>0.002706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            features  importance\n",
       "1         html_ratio    0.540563\n",
       "0        image_ratio    0.456731\n",
       "2  lengthyLinkDomain    0.002706"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X.columns\n",
    "feature_importances = cls.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({'features': features, 'importance': feature_importances})\n",
    "features_df.sort_values('importance', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Evaluate the Random Forest model using cross-validation; increase the number of estimators and view how that improves predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest with 20 trees:  0.556043674123\n",
      "Random forest with 100 trees:  0.561609416485\n"
     ]
    }
   ],
   "source": [
    "cls_20 = RandomForestClassifier(n_estimators=20)\n",
    "cls.fit(X, y)\n",
    "print 'Random forest with 20 trees: ', cross_val_score(cls_20, X, y, scoring='roc_auc', cv=5).mean()\n",
    "\n",
    "cls_100 = RandomForestClassifier(n_estimators=100)\n",
    "cls.fit(X, y)\n",
    "print 'Random forest with 100 trees: ', cross_val_score(cls_100, X, y, scoring='roc_auc', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Practice: Evaluate Random Forest Using GridSearch\n",
    "\n",
    "1. Continue adding input variables to the model that you think may be relevant\n",
    "2. For each feature:\n",
    "  - Evaluate the model for improved predictive performance using cross-validation\n",
    "  - Evaluate the _importance_ of the feature\n",
    "3. **Bonus**: Just like the 'recipe' feature, add in similar text features and evaluate their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a feature that represents the number of words in the article\n",
    "df['num_words'] = df['body'].fillna('').str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    return x.map(lambda x: (x - mu) / sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'image_ratio', \n",
    "    'html_ratio',  \n",
    "    'num_words', \n",
    "    'has_recipe', \n",
    "    'avglinksize', \n",
    "]\n",
    "\n",
    "for feat in features:\n",
    "    df[feat + '_norm'] = normalize(df[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "features_norm = [f + '_norm' for f in features]\n",
    "target = 'label'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "cls = GradientBoostingClassifier(n_estimators=50)\n",
    "cls.fit(X, y)\n",
    "\n",
    "cv = cross_val_score(cls, X, y, scoring='roc_auc', cv=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval:  (0.7208079068241471, 0.8205646169228846)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "bottom = pd.Series(cv).quantile(0.025)\n",
    "top = pd.Series(cv).quantile(0.975)\n",
    "\n",
    "print 'Confidence Interval: ', (bottom, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has_recipe</td>\n",
       "      <td>0.395173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>html_ratio</td>\n",
       "      <td>0.179032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avglinksize</td>\n",
       "      <td>0.148321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_words</td>\n",
       "      <td>0.148121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_ratio</td>\n",
       "      <td>0.129353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  importance\n",
       "3   has_recipe    0.395173\n",
       "1   html_ratio    0.179032\n",
       "4  avglinksize    0.148321\n",
       "2    num_words    0.148121\n",
       "0  image_ratio    0.129353"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare feature importance with engineered features in model\n",
    "features = X.columns\n",
    "feature_importances = cls.feature_importances_\n",
    "\n",
    "features_df = pd.DataFrame({'features': features, 'importance': feature_importances})\n",
    "features_df.sort_values('importance', inplace=True, ascending=False)\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
