{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "path = '../../data/simple_demographics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print out the first 5 rows of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Basic Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods available include:\n",
    "    \n",
    "    .min() - Compute minimum value\n",
    "    .max() - Compute maximum value\n",
    "    .mean() - Compute mean value\n",
    "    .median() - Compute median value\n",
    "    .mode() - Compute mode value(s)\n",
    "    .count() - Count the number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remember, a dataset can have multiple modes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Box Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot is a standardized way of displaying the distribution of the data. It's made up of two parts:\n",
    "\n",
    "** The Box **\n",
    "- extends from the 25th percentile to the 75th percentile\n",
    "- the difference between the two ends is known as the inter-quartile range (IQR)\n",
    "- the median, or 50th percentile, is represented with a line in the box\n",
    "\n",
    "** The Whiskers **\n",
    "- the lower whisker extends to the greater of the minimum of the data or the 25th percentile minus 1.5 times the IQR\n",
    "```\n",
    "a = df.min()\n",
    "iqr = df.quantile(0.75) - df.quantile(0.25)\n",
    "b = df.quantile(0.25) - 1.5 * iqr\n",
    "lower_whisker = max(a, b)\n",
    "```\n",
    "- the upper whisker extends to the lesser of the maximum of the data or the 75th percentile plush 1.5 times the IQR\n",
    "```\n",
    "a = df.max()\n",
    "iqr = df.quantile(0.75) - df.quantile(0.25)\n",
    "b = df.quantile(0.75) + 1.5 * iqr\n",
    "upper_whisker = min(a, b)\n",
    "```\n",
    "- if the whiskers don't reach to the `min` or `max` of the data, then points outside the whiskers are indicated on the box plot\n",
    "- **NOTE: the whiskers always extend to an actual point in the data! Therefore, if the whiskers extend to `1.5 * IQR` then they will actually show as extending to the most extreme data point within the whisker range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use a box plot to visualize the age data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use a box plot to visualize the income data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write the code to figure out the exact points for all of the parts of the boxplot of the 'health' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Standard Deviation and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance** = measures how far a set of numbers are spread out from their average value\n",
    "<br>\n",
    "**Standard Deviation** = square root of the variance (measured in the same units as the data)\n",
    "\n",
    "<img(src='images/samplevarstd.png', style=\"width: 60%; height: 60%\")>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the variance of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter vs. Statistic\n",
    "\n",
    "**Parameter** = characteristic about a ***population***\n",
    "<br>\n",
    "**Statistic** = characteristic about a ***sample***\n",
    "\n",
    "Parameters are normally *unknown* -- we are not able to calculate characteristics about a population, but we can calculate them for a sample.\n",
    "- For example, consider the average height for an American male\n",
    "- The population in this case is **all American males**\n",
    "- It's not feasible (nor possible) to measure **every** American male to calculate the mean -- if we could, that mean would be a **parameter of the population**\n",
    "- We can, however, get data from a sample of men -- the mean of this sample is considered a **sample statistic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error\n",
    "\n",
    "The standard error of a parameter is the standard deviation of its sampling distribution. In other words, the standard error measures the variance of a sample statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate 1000 samples of 10000 draws from a normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Take a look at the data -- it has 10,000 rows and 1,000 columns (each column is a sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the population is `0`, however the mean of each sample varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a line chart of the means of each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation of these 1,000 means is called the standard error of the mean. It's a measure of how far your sample mean is likely to be from the true population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the means of each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you only have one sample? The standard error of the mean can also be calculated by dividing the sample standard deviation by the square root of the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the standard error of the mean using a random column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normal distribution is a key assumption to many models we will be using later. But what is normal?\n",
    "\n",
    "- The graph of the normal distribution depends on two factors - the **mean** and the **standard deviation**.\n",
    "- The mean of the distribution determines the location of the center of the graph\n",
    "- The standard deviation determines the height of the graph -- when the standard deviation is large, the curve is short and wide; when the standard deviation is small, the curve is tall and narrow. \n",
    "- All normal distributions look like a symmetric, bell-shaped curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few normal distributions that all have the same mean but different standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate 4 normal distributions each with a mean of 0, but with these standard deviations: [0.5, 1.0, 1.5, 2.0]\n",
    "normal = pd.DataFrame(\n",
    "    data={\n",
    "        'std: 0.5': np.random.normal(loc=0, scale=0.5, size=10000),\n",
    "        'std: 1.0': np.random.normal(loc=0, scale=1.0, size=10000),\n",
    "        'std: 1.5': np.random.normal(loc=0, scale=1.5, size=10000),\n",
    "        'std: 2.0': np.random.normal(loc=0, scale=2.0, size=10000)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verify we generated the data we wanted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot all of the columns using a 'density' plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness\n",
    "\n",
    "In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a random variable about its mean. The skewness value can be positive or negative, or even undefined.\n",
    "\n",
    "<img(src='images/skew.png', style=\"width: 70%; height: 70%\")>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can use the scipy library for this\n",
    "from scipy.stats import skewnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate random variables from a skewed, normal distribution\n",
    "right_skewed = skewnorm.rvs(a=10.0, loc=0.0, scale=1.0, size=10000)\n",
    "left_skewed = skewnorm.rvs(a=-10.0, loc=0.0, scale=1.0, size=10000)\n",
    "\n",
    "skew = pd.DataFrame(\n",
    "    data={\n",
    "        'Right-skewed': right_skewed,\n",
    "        'Left-skewed': left_skewed\n",
    "    },\n",
    ")\n",
    "\n",
    "skew.plot(kind='density', figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's take a closer look at the right-skewed distribution\n",
    "right_skew = skew['Right-skewed']\n",
    "\n",
    "# Plot the skewed data\n",
    "\n",
    "\n",
    "# Plot a black line at the mean\n",
    "\n",
    "\n",
    "# Plot a red line at the median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem is a fundamental tool in statistics. It says, with some assumptions, that sampling distributions are normal with a specific mean and standard deviation. It's a vital tool in data science when working with large data sets. Often a random sample (or many random samples) can tell us crucial information about a much larger dataset.\n",
    "\n",
    "For example, if you work at a large social media company and you want to estimate the distribution of the ages of your users for targetting ads, you could extract the ages of hundreds of millions of users from your database and compute the distribution. This will take a lot of time and effort, and it's usually enough to simply look at a much smaller but random subset of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Distributions\n",
    "\n",
    "Usually we do not know the true distribution of our data so we study it by looking at the distribution of random samples. It turns out that we can often identify the underlying \"true\" distribution within any necessary degree of approximation as long as we can obtain enough data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customers Arriving to Our Store\n",
    "\n",
    "Let's say that we want to model the arrival of customers to our store. Each customer arrival is independent (i.e. the time one customer arrives doesn't depend on the time that any other customer arrives). The time between customer arrivals can be modeled with an exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our **population** assume we know that **50 customers** arrive per hour on average. We want to know the expected time between each arrival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can use these functions to plot an exponential distribution\n",
    "\n",
    "lam = 50 / 60.\n",
    "\n",
    "def exp_pdf(x):\n",
    "    return lam * np.exp(-lam * x)\n",
    "\n",
    "def exp_cdf(x):\n",
    "    return 1 - np.exp(-lam * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the PDF of an exponential distribution where 50 customers arrive every 60 minutes\n",
    "x = np.arange(0, 5, 0.1)\n",
    "pd.Series(x, index=x).apply(exp_pdf).plot(kind='line', figsize=(10,8), xlim=(0, 5))\n",
    "\n",
    "# Add lines to highlight the mean and median\n",
    "\n",
    "\n",
    "print 'Mean of Distribution: {}'.format(1 / lam)\n",
    "print 'Median of Distribution: {}'.format(lam)\n",
    "print 'Standard Deviation of Distribution: {}'.format(1 / lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **probability density function (PDF)**. The x-value is the time between two customers and the y-value is the probability of seeing that x value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the CDF of an exponential distribution where 50 customers arrive every 60 minutes\n",
    "x = np.arange(0, 5, 0.1)\n",
    "pd.Series(x, index=x).apply(exp_cdf).plot(kind='line', figsize=(10,8), xlim=(0, 5))\n",
    "\n",
    "# Add lines to highlight that lambda is the median of the distribution\n",
    "plt.vlines(50 / 60., ymin=0, ymax=1.0, linewidth=3.0, color='black')\n",
    "plt.hlines(0.5, xmin=0, xmax=5.0, linewidth=3.0, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **cumulative density function (PDF)**. The x-value is the time between two customers and the y-value is the probability of seeing that x value *or less*. The median of a distribution is the corresponding value on the x axis for a y-value of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at random samples from our distribution. Re-run the following cell serveral times to see how the samples change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate random samples from an exponential distribution where 50 customers arrive every 60 minutes\n",
    "customers = pd.Series(np.random.exponential(scale=1/lam, size=100))\n",
    "\n",
    "# Plot the samples using a histogram\n",
    "\n",
    "\n",
    "# Add a label for the x-axis\n",
    "\n",
    "\n",
    "# Print out the sample mean and standard deviation\n",
    "print 'Mean of Sample: {}'.format(customers.mean())\n",
    "print 'Standard Deviation of Sample: {}'.format(customers.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram of our random sample looks approximately like our distribution and the sample has a mean and standard deviation in the ballpark of our true parameter values. Let's take a look at the distribution of the means of many such random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate random samples from an exponential distribution where 50 customers arrive every 60 minutes\n",
    "customers = pd.DataFrame(np.random.exponential(scale=1/lam, size=(1000, 20)))\n",
    "\n",
    "# Plot the samples using a histogram\n",
    "\n",
    "# Add a label for the x-axis\n",
    "\n",
    "\n",
    "# Print out the mean and standard deviation of our sample means\n",
    "print 'Mean of Sample Means: {}'.format(customers.mean().mean())\n",
    "print 'Standard Deviation of Sample Means: {}'.format(customers.mean().std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the means is much closer to our actual mean. Let's take many samples and see if things get better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate random samples from an exponential distribution where 50 customers arrive every 60 minutes\n",
    "customers = pd.DataFrame(np.random.exponential(scale=1/lam, size=(1000, 10000)))\n",
    "\n",
    "# Plot the samples using a histogram\n",
    "\n",
    "\n",
    "# Add a label for the x-axis\n",
    "\n",
    "\n",
    "# Print out the mean and standard deviation of our sample means\n",
    "print 'Mean of Sample Means: {}'.format(customers.mean().mean())\n",
    "print 'Standard Deviation of Sample Means: {}'.format(customers.mean().std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's really close! The distribution looks like a normal distribution too. Let's do a quick curve fit (called a kernel density estimate). First we'll look at a large sample, and then at the distribution of means of many samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First, plot one sample\n",
    "customers.iloc[0].plot(\n",
    "    kind='hist', \n",
    "    figsize=(10, 8), \n",
    "    ec='black', \n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "customers.iloc[0].plot(\n",
    "    kind='density',\n",
    "    figsize=(10, 8), \n",
    "    secondary_y=True, \n",
    "    color='black', \n",
    "    xlim=(0, 15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Then plot all of the sample means\n",
    "customers.mean().plot(\n",
    "    kind='hist', \n",
    "    figsize=(10, 8), \n",
    "    ec='black', \n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "customers.mean().plot(\n",
    "    kind='density',\n",
    "    figsize=(10, 8), \n",
    "    secondary_y=True, \n",
    "    color='black', \n",
    "    xlim=(1.0, 1.4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem\n",
    "\n",
    "The [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) explains what we've just observed. It says that, as the size $n$ of a sample increases, that:\n",
    "* the mean of the sample $\\bar{x}$ converges to the mean of the true distribution, and\n",
    "* the standard deviation $s$ of the sample is the same as the true standard deviation $\\sigma$\n",
    "\n",
    "The sampling distribution of the means has:\n",
    "* The same mean as the original distribution\n",
    "* A standard deviation $\\hat{\\sigma}$ given by the true standard deviation divided by $\\sqrt{n}$:\n",
    "$$\\sigma' = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "This quantity is usually referred to as the *standard error*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we typically use these results as follows. Take a large random sample and calculate the sample mean $\\bar{x}$ and the sample deviation $s$. If we were to do this repeatedly, then 95% of the time, the true mean would lie in the interval:\n",
    "$$(\\bar{x} - 2s, \\bar{x} + 2s)$$\n",
    "\n",
    "As the sample size $n$ gets large, the error $s$ gets small. So for a large enough sample we can get a very good approximation of the true mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals are one of the most commonly used statistical methods to summarize\n",
    "uncertainty in parameter estimates from data analyses.\n",
    "\n",
    "A confidence interval (CI) is the range of values the true value in the population is expected to fall within. It is based on a certain level of confidence.\n",
    "\n",
    "The width of the CI changes with changes in sample size. The width of the confidence interval is larger with small sample sizes. You donâ€™t have enough data to get a clear picture of what is going on so your range of possible values is wider. The width of the CI decreases with an increasing sample size $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping\n",
    "\n",
    "A common way of creating confidence intervals is through a process called bootstrapping. Essentially, bootstrapping just means sampling with replacement. Through this process, we can turn one sample of 1,000 observations into 1,000 samples of 1,000 observations.\n",
    "\n",
    "Let's try calculating the confidence interval around the average number of days in a month users are active on our website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the active_users dataset\n",
    "path = '../../data/active_users.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the data using a histogram\n",
    "\n",
    "# Add a label for the x-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use np.random.choice to generate 1,000 bootstrapped samples, each with 1,000 observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of sample means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's calculate the 95% confidence interval\n",
    "# It extends from the 2.5th percentile to the 97.5th percentile\n",
    "\n",
    "\n",
    "print '95% Confidence Interval: [{bottom}, {top}]'.format(**locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's add the 95% confidence interval to the graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Hypothesis Testing and P-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closely related to confidence intervals is **hypothesis testing**. Generally speaking, you start with a **null hypothesis** and an **alternative hypothesis** - a hypothesis that is the opposite of the null. Then, you check whether the data supports **rejecting the null hypothesis** or **failing to reject the null hypothesis**, at some level of significance.\n",
    "\n",
    "Note that \"failing to reject\" the null is ***not*** the same as \"accepting\" the null hypothesis. Your alternative hypothesis may indeed be true, but you don't necessarily have enough data to show that yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Tailed Hypothesis Test\n",
    "\n",
    "We can use a one-tailed hypothesis test to find out if the true parameter (e.g., mean, proportion, difference in means, differences in proportions) is greater than ***or*** less than a value, **but not both**. Because of this, in practice, most data scientists tend to use two-tailed hypothesis tests.\n",
    "\n",
    "### Two-Tailed Hypothesis Test\n",
    "\n",
    "Suppose we want to test the hypothesis that males have more friends on social media platforms than females. Our null hypothesis would be that the relative difference in friends between males and females is 0 and the alternative hypothesis would be that the relative difference is not 0 (can be greater than or less than 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the friends dataset\n",
    "path = '../../data/friends.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the average number of friends between males and females\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the distributions as density plot\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "for label, data in friends.groupby('gender'):\n",
    "    data['friends'].plot(kind='density', ax=ax, label=label, legend=True, xlim=(0, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate 95% confidence intervals around the mean for males then for females\n",
    "# If their confidence intervals overlap, then we do not reject the null hypothesis\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
